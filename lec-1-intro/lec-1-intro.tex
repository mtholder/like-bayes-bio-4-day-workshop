\documentclass[landscape]{foils} 
\input{../preamble.tex}
\usepackage{pdfpages}
\begin{document}

\unitlength=1mm

\begin{center}
{\Large {\bf Likelihood and Bayesian Methods in Biology}}\\
\vskip 5mm

{\large
\url{http://mtholder.github.io/like-bayes-bio/}\par
Mark T. Holder (Univ.~Kansas, USA) \\
\large Thanks to John Kelly and Ford Ballantyne \par
\vskip 1em
HCMR\\
15-18 June, 2015.
}
\end{center}

\myNewSlide
\section*{Goals of the course}
\begin{itemize}
  \item Cover the basic theory associated with point estimation, interval 
  estimation, and hypothesis testing in the maximum likelihood and Bayesian 
  paradigms.
  \item Use some simple computer programs in Python and R to demonstrate that
  it is not too difficult to apply this form of statistical theory.
  \item The examples I use are all ``toy'' simulated datasets, so we will not 
  really get into real biology.
\end{itemize}


\myNewSlide
\section*{Schedule}
\begin{itemize}
  \item Introduction to likelihoods and basic scripts for ML-based confidence intervals (today)
  \item Tuesday: he numerical approaches used to optimize likelihoods, and dealing with multi-parameter models.
  \item Bayesian Introduction: Bayesian inference and Markov chain Monte Carlo
  \item Using model-jumping MCMC to perform model averaging.
\end{itemize}

\myNewSlide
The two competing approaches to statistics:
\begin{compactitem}
  \item frequentist:
  \begin{itemize}
    \item {\bf probability}: the relative frequency of an event if you were able to repeat a trial an infinite number of times.
    \item {\bf goal}: make an argument like ``This result differs significantly from what we would expect if the null model were true. Either the null is not true or we experienced an unusually large amount of sampling error.''
    The $P$-value summarizes how unusual it would be to see results like yours if the null hypothesis were true.
    \item {\bf we make probability statements about}: the performance of our estimation procedures.
  \end{itemize}
  \item Bayesian:
  \begin{itemize}
    \item {\bf probability}: degree of belief
    \item {\bf goal}: express the uncertainty of an estimate:
    ``Given a model and what one knew before one collected the data, one should now believe that the $\Pr(\mu>2.3)\approx 0.87$''
    \item {\bf we make probability statements about}: the true values of parameters/models.
  \end{itemize}
\end{compactitem}

\myNewSlide
\section*{The frequentist ``recipe'' for hypothesis testing}
\begin{compactenum}
  \item Ask a scientific question.
  \item State your question in terms of $H_0$ and $H_A$
  \item Collect a random sample
  \item Calculate a value of a test statistic
  \item Determine $P$-value:
  \begin{compactenum}
    \item What values of the test statistic are expected under $H_0$?
    \item How does the observed test statistic differ from these expectations?
    \item What is the probability of observing a value of a test statistic this extreme or more extreme if the $H_0$ is true? -- this is the $P$-value.
  \end{compactenum}
  \item Make a decision about $H_0$ and $H_A$
  \item Answer your question and report the results.
\end{compactenum}

\myNewSlide
\section*{Question: Where does ``likelihood'' fit in?}
{\bf Answer:} the choice of a test statistic.\\

Law of likelihood: ``the extent to which the evidence supports one parameter value or hypothesis against another is equal to the ratio of their likelihoods''\footnote{\href{https://en.wikipedia.org/wiki/Likelihood_principle#The_law_of_likelihood}{Wikipedia} -- everyone's favorite source of assertions}

Using a likelihood ratio as a test statistic $\rightarrow$ powerful test.

Using maximum likelihood as an estimator: $\rightarrow$ powerful, and statistically consistent (for well-behaved models) estimator.

\myNewSlide
\section*{$P$-values for likelihood ratios}

Sometimes it is analytically tractable to calculate a null distribution.

More commonly, we test null models that are nested within a richer model,
so we use the following trick:

For large sample sizes,\\
if you calculate a likelihood under a model with $x$ extra parameters, \\
the ratio of likelihoods between the larger model and the true model \\
will
be distributed according to $\chi^2_{df=x}$

This is often referred to as the ``likelihood ratio test.''

\end{document}   
